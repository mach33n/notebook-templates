{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Workflow\n",
    "\n",
    "## 1. Define the Problem\n",
    "\n",
    "1. What is the problem? Provide formal and informal definitions.\n",
    "2. Why does the problem need to be solved? Motivation, benefits, how it will be used.\n",
    "3. How would I solve the problem? Describe how the problem would be solved manually to flush domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This problem definition\n",
    "1. Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. \n",
    "\n",
    "#### Variable Descriptions\n",
    "1. Variable\t -             Description\n",
    "2. Loan_ID -\t               Unique Loan ID\n",
    "3. Gender -\t               Male/ Female\n",
    "4. Married -               Applicant married (Y/N)\n",
    "5. Dependents -\t          Number of dependents\n",
    "6. Education -\t          Applicant Education (Graduate/ Under Graduate)\n",
    "7. Self_Employed -\t          Self employed (Y/N)\n",
    "8. ApplicantIncome -\t      Applicant income\n",
    "9. CoapplicantIncome -\t      Coapplicant income\n",
    "10. LoanAmount -          Loan amount in thousands\n",
    "11. Loan_Amount_Term -\t      Term of loan in months\n",
    "12. Credit_History -      credit history meets guidelines\n",
    "13. Property_Area -          Urban/ Semi Urban/ Rural\n",
    "14. Loan_Status\t -        Loan approved (Y/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data\n",
    "1. Data Selection. Availability, what is missing, what can be removed.\n",
    "2. Data Preprocessing. Organize selected data by formatting, cleaning and sampling.\n",
    "3. Data Transformation. Feature engineering using scaling, attribute decomposition and attribute aggregation.\n",
    "4. Data visualizations such as with histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"lp_train.csv\") #Reading the dataset in a dataframe using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show data that needs to be added to system\n",
    "df.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Loan_ID', 'Loan_Status', 'Dependents', 'Self_Employed', 'Married', 'Education', 'Property_Area', 'Gender']\n"
     ]
    }
   ],
   "source": [
    "# show all non number columns\n",
    "all_cols = df.columns\n",
    "num_cols = df._get_numeric_data().columns\n",
    "nonum_cols = list(set(all_cols) - set(num_cols))\n",
    "print(nonum_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean and update missing or nonum data\n",
    "# Gender               13\n",
    "df['Gender'].fillna('Male',inplace=True)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\"])\n",
    "\n",
    "#Married               3\n",
    "df['Married'].fillna('Yes',inplace=True)\n",
    "df = pd.get_dummies(df, columns=[\"Married\"])\n",
    "\n",
    "#Dependents           15\n",
    "df['Dependents'].fillna('0',inplace=True)\n",
    "df['Dependents'] = pd.to_numeric(df['Dependents'].str.replace(r'[^-\\d.]', ''))\n",
    "\n",
    "#Self_Employed        32\n",
    "df['Self_Employed'].fillna('No',inplace=True)\n",
    "df = pd.get_dummies(df, columns=[\"Self_Employed\"])\n",
    "\n",
    "#LoanAmount           22\n",
    "df['LoanAmount'].fillna(df['LoanAmount'].mean(), inplace=True)\n",
    "\n",
    "#Loan_Amount_Term     14 - assume way more 360 so these are probably 360\n",
    "df['Loan_Amount_Term'].fillna(360,inplace=True)\n",
    "\n",
    "\n",
    "#Credit_History       50 - assume if there is no data then credit history is not valid\n",
    "df['Credit_History'].fillna(0,inplace=True)\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"Education\"])\n",
    "df = pd.get_dummies(df, columns=[\"Property_Area\"])\n",
    "#df = pd.get_dummies(df, columns=[\"Loan_Status\"])\n",
    "\n",
    "df = df.drop([\"Loan_ID\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependents                 0\n",
      "ApplicantIncome            0\n",
      "CoapplicantIncome          0\n",
      "LoanAmount                 0\n",
      "Loan_Amount_Term           0\n",
      "Credit_History             0\n",
      "Loan_Status                0\n",
      "Gender_Female              0\n",
      "Gender_Male                0\n",
      "Married_No                 0\n",
      "Married_Yes                0\n",
      "Self_Employed_No           0\n",
      "Self_Employed_Yes          0\n",
      "Education_Graduate         0\n",
      "Education_Not Graduate     0\n",
      "Property_Area_Rural        0\n",
      "Property_Area_Semiurban    0\n",
      "Property_Area_Urban        0\n",
      "dtype: int64\n",
      "['Loan_Status']\n"
     ]
    }
   ],
   "source": [
    "# Recheck\n",
    "print(df.apply(lambda x: sum(x.isnull()),axis=0))\n",
    "# show all non number columns\n",
    "all_cols = df.columns\n",
    "num_cols = df._get_numeric_data().columns\n",
    "nonum_cols = list(set(all_cols) - set(num_cols))\n",
    "print(nonum_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome_var = 'Loan_Status'\n",
    "predictor_var = [x for x in df.columns if x not in [outcome_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X = df[predictor_var].values\n",
    "Y = df[outcome_var]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spot Check Algorithms\n",
    "1. Test harness with default values.\n",
    "2. Run family of algorithms across all the transformed and scaled versions of dataset.\n",
    "3. View comparisons with box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Validate Model on Test Data **\n",
      "1. Accuracy: 0.7479674796747967\n",
      "2. Confusion Matrix:\n",
      "Predicted   N   Y  All\n",
      "True                  \n",
      "N          16  23   39\n",
      "Y           8  76   84\n",
      "All        24  99  123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)\n",
    "print(\"\\n** Validate Model on Test Data **\")\n",
    "print(\"1. Accuracy: {}\".format(accuracy_score(Y_validation, predictions)))\n",
    "print(\"2. Confusion Matrix:\\n{}\".format(pd.crosstab(Y_validation, predictions, rownames=['True'], colnames=['Predicted'], margins=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improve Results (Tuning)\n",
    "1. Algorithm Tuning: discovering the best models in model parameter space. This may include hyper parameter optimizations with additional helper services.\n",
    "2. Ensemble Methods: where the predictions made by multiple models are combined.\n",
    "3. Feature Engineering: where the attribute decomposition and aggregation seen in data preparation is tested further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Validate Model on Test Data **\n",
      "1. Accuracy: 0.7886178861788617\n",
      "2. Confusion Matrix:\n",
      "Predicted   N   Y  All\n",
      "True                  \n",
      "N          19  20   39\n",
      "Y           6  78   84\n",
      "All        25  98  123\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)\n",
    "print(\"\\n** Validate Model on Test Data **\")\n",
    "print(\"1. Accuracy: {}\".format(accuracy_score(Y_validation, predictions)))\n",
    "print(\"2. Confusion Matrix:\\n{}\".format(pd.crosstab(Y_validation, predictions, rownames=['True'], colnames=['Predicted'], margins=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Present Results\n",
    "1. Context (Why): how the problem definition arose in the first place.\n",
    "2. Problem (Question): describe the problem as a question.\n",
    "3. Solution (Answer): describe the answer the the question in the previous step.\n",
    "4. Findings: Bulleted lists of discoveries you made along the way that interests the audience. May include discoveries in the data, methods that did or did not work or the model performance benefits you observed.\n",
    "5. Limitations: describe where the model does not work.\n",
    "6. Conclusions (Why+Question+Answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
